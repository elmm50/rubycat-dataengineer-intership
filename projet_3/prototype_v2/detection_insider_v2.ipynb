{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for preprocessing the raw data, the steps are :\n",
    "# Event aggregation\n",
    "# Sorting by time\n",
    "def data_preprocessing(data1,data2,data3,data4):\n",
    "          # Loading files\n",
    "          device_df=pd.read_csv(data1)\n",
    "          logon_df=pd.read_csv(data2)\n",
    "          email_df=pd.read_csv(data3)\n",
    "          file_df=pd.read_csv(data4)\n",
    "          \n",
    "\n",
    "\n",
    "          # Show shape\n",
    "          print(\"Shape of \",data1,\" : \",device_df.shape,\"\\n\") \n",
    "          print(\"Shape of \",data2,\" : \",logon_df.shape,\"\\n\") \n",
    "          print(\"Shape of \",data3,\" : \",email_df.shape,\"\\n\") \n",
    "          print(\"Shape of \",data4,\" : \",file_df.shape,\"\\n\") \n",
    "          \n",
    "          # Event aggregation\n",
    "          merged_df=pd.concat([device_df,logon_df,email_df,file_df])\n",
    "\n",
    "\n",
    "          # Replacing the date column with different format\n",
    "          #merged_df['date']=pd.to_datetime(merged_df['date'],dayfirst=False)\n",
    "\n",
    "          # Sorting by date\n",
    "          #sorted_df=merged_df.sort_values(by=['date'])\n",
    "          #print(\" First rows of merged Dataframes sorted by date : \",\"\\n\",sorted_df.head(),\"\\n\")\n",
    "          print(\" First rows of merged Dataframes sorted by date : \",\"\\n\",merged_df.head(),\"\\n\")\n",
    "          \n",
    "          return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df=data_preprocessing('device.csv','logon.csv','email.csv','file.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_a_user(user,user_abnormal_events,sorted_df):\n",
    "          \n",
    "          # For User = user\n",
    "          user_1=sorted_df[sorted_df['user']==user]\n",
    "          # Show\n",
    "          print(\"First rows of \",user,\" events : \",\"\\n\",user_1.head(),\"\\n\")\n",
    "          print('Shape : ',user_1.shape,\"\\n\")\n",
    "          \n",
    "          \n",
    "          \n",
    "          #Â Importing the abnormal events \n",
    "          events_user_1_abnormal=pd.read_csv(user_abnormal_events,header=None)\n",
    "          \n",
    "          \n",
    "          # We keep only normal events \n",
    "          # The id of abnormal events in a list \n",
    "          id_abnormal=events_user_1_abnormal[1]\n",
    "          # We drop the corresponding abnormal events\n",
    "          user_1_normal=user_1 \n",
    "          for id in id_abnormal:\n",
    "                    user_1_normal=user_1_normal[~(user_1_normal['id']==id)]\n",
    "          # Show\n",
    "          print(\"First rows of \",user,\" normal events : \",\"\\n\",user_1_normal.head(),\"\\n\")\n",
    "          print('shape : ',user_1_normal.shape)\n",
    "\n",
    "\n",
    "\n",
    "          # We take only the abnormal events\n",
    "          user_1_abnormal=pd.DataFrame([],columns=['id','date','user','pc','activity'])\n",
    "          for id in id_abnormal:\n",
    "                    user_1_abnormal=pd.concat([user_1_abnormal,user_1[(user_1['id']==id)]])   \n",
    "          user_1_abnormal\n",
    "          print(\"First rows of \",user,\" abnormal events : \",\"\\n\",user_1_abnormal.head(),\"\\n\")\n",
    "          print('Shape : ',user_1_abnormal.shape)\n",
    "          \n",
    "          \n",
    "          # Creating the DataFrame of vector feature of all events\n",
    "          table_feature_vector_user_1=raw_data_to_Table_of_Feature_Vectors(user_1)\n",
    "          print(\"First rows of \",user,\" Table of Feature Vectors with Days including normal and abnormal events : \",\"\\n\",table_feature_vector_user_1,\"\\n\")\n",
    "          print(\"Shape : \",table_feature_vector_user_1.shape)\n",
    "          \n",
    "\n",
    "          # Creating the DataFrame of vector feature for the abnormal events\n",
    "          table_feature_vector_user_1_abnormal=raw_data_to_Table_of_Feature_Vectors(user_1_abnormal)\n",
    "          # We will remove the days with abnormal events and keep only days with normal events in table_feature_vector_user_1_normal\n",
    "          # and we will keep all events (normal and abnormal) in table_feature_vector_user_1\n",
    "          abnormal_day=table_feature_vector_user_1_abnormal['date']\n",
    "          print(\"Days that have abnormal events : \",'\\n',abnormal_day,\"\\n\")\n",
    "\n",
    "          # We will create a table with only days with normal events\n",
    "          table_feature_vector_user_1_normal=table_feature_vector_user_1\n",
    "          for day in abnormal_day:\n",
    "                    table_feature_vector_user_1_normal=table_feature_vector_user_1_normal[~(table_feature_vector_user_1_normal['date']==day)]\n",
    "          print(\"First rows of \",user,\" Table of Feature Vectors with Days including only normal events : \",\"\\n\",table_feature_vector_user_1_normal,\"\\n\")\n",
    "          print(\"Shape : \",table_feature_vector_user_1_normal.shape)\n",
    "          \n",
    "\n",
    "          # Creating a vector insiderthreat(like y in tutoriels) with (1/0) where the day is abnormal/normal  if in this day have abnormal events \n",
    "          date_for_insiderthreat=table_feature_vector_user_1['date']\n",
    "          date_for_insiderthreat.tolist()\n",
    "          insiderthreat = date_for_insiderthreat.isin(abnormal_day)*1\n",
    "          insiderthreat=insiderthreat.tolist()\n",
    "          print(\"insiderthreat vector is the true output(y), the days where there was abnormal events : \",\"\\n\",insiderthreat)\n",
    "          \n",
    "          \n",
    "          \n",
    "          \n",
    "          # We drop the date columns for model training purpuse\n",
    "          table_feature_vector_user_1_normal=table_feature_vector_user_1_normal.drop(['date'],axis=1)\n",
    "          table_feature_vector_user_1=table_feature_vector_user_1.drop(['date'],axis=1)\n",
    "\n",
    "\n",
    "          return table_feature_vector_user_1, table_feature_vector_user_1_normal, insiderthreat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_df=pd.read_csv('email.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
